{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents <a id='back'></a>\n",
    "1. [Introduction](#introduccion)\n",
    "2. [Objective](#objetivo)\n",
    "3. [Data and Libraries](#datos-y-librerias)\n",
    "    1. [Libraries](#librerias)\n",
    "    2. [Data](#datos)\n",
    "    3. [Understanding the Data](#understanding-the-data)\n",
    "    4. [Data Preparation](#preparacion-de-los-datos)\n",
    "4. [Model: Decision Tree](#decision-tree)\n",
    "5. [Model: Random Forest](#random-forest)\n",
    "6. [Model: Logistic Regression](#regresion-logistica)\n",
    "7. [Testing](#testeo)\n",
    "8. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduccion\"></a>\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will create a model that can analyze customer behavior and recommend one of Megaline's new plans:\n",
    "\n",
    "- Smart\n",
    "- Ultra\n",
    "\n",
    "To achieve this, we will analyze the data using 3 types of models:\n",
    "\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Logistic Regression\n",
    "\n",
    "For each of these models, we will explore and calibrate their hyperparameters to seek the highest possible accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"objetivo\"></a>\n",
    "## Objetive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a model that can analyze customer behavior and recommend one of Megaline's new plans:\n",
    "\n",
    "- Smart\n",
    "- Ultra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"datos-y-librerias\"></a>\n",
    "## Data and libreries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"librerias\"></a>\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the libraries that will be useful for our analysis.\n",
    "import pandas as pd\n",
    "from sklearn import set_config\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"datos\"></a>\n",
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the data from each table separately.\n",
    "try:\n",
    "    df = pd.read_csv('C:\\\\Users\\\\Alejandro\\\\Downloads\\\\users_behavior.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"The file was not found in the specified location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"understanding-the-data\"></a>\n",
    "### Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly inspect the data to understand what we're training our model with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0\n",
       "5   58.0   344.56      21.0  15823.37         0\n",
       "6   57.0   431.64      20.0   3738.90         1\n",
       "7   15.0   132.40       6.0  21911.60         0\n",
       "8    7.0    43.39       3.0   2538.67         1\n",
       "9   90.0   665.41      38.0  17358.61         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take advantage of the fact that this DataFrame consists exclusively of numbers and describe it statistically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preparacion-de-los-datos\"></a>\n",
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although DataFrames often have missing data, this is not the case this time. However, that does not mean we should not prepare the data before working with it. To train, validate, and test our model, we need to take 2 steps beforehand. These are:\n",
    "\n",
    "- Split the data to have different data groups; in this case, we will leave 20% for validation and another 20% for testing, with the rest for training.\n",
    "- Create targets and features for our model, considering training, validation, and testing. In this case, we consider the final column `is_ultra` as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we separate the test group\n",
    "df_rest, df_test = train_test_split(df, test_size=0.2, random_state=54321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2571, 5)\n",
      "(643, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_rest.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we split into training and validation\n",
    "df_train, df_valid = train_test_split(df_rest, test_size=0.25, random_state=54321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create targets and features for our model\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento:\n",
      "(1928, 4)\n",
      "(1928,)\n",
      "\n",
      "Validación:\n",
      "(643, 4)\n",
      "(643,)\n",
      "\n",
      "Testeo:\n",
      "(643, 4)\n",
      "(643,)\n"
     ]
    }
   ],
   "source": [
    "# Let's check the final sizes of our DataFrames\n",
    "print('Training:')\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print()\n",
    "print('Validationn:')\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n",
    "print()\n",
    "print('Testing:')\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will use the same data across each model, it is more convenient to do this in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"decision-tree\"></a>\n",
    "## Model: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the decision tree, adjusting its depth and number of leaves. We will change several variables, taking advantage of the model's high processing speed. This allows us to experiment a bit more with the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del mejor modelo en el conjunto de validación (depth = 7): 0.8429237947122862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, min_samples_leaf=13, random_state=54321)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree = 0\n",
    "best_depth = 0\n",
    "best_leaf = 0\n",
    "score = 0\n",
    "for depth in range(1, 20): # select the hyperparameter range\n",
    "    for leaf in range(1,20): \n",
    "        tree = DecisionTreeClassifier(random_state=54321, max_depth=depth, min_samples_leaf=leaf) # configure the number of trees\n",
    "        tree.fit(features_train,target_train) # train the model on the training set\n",
    "        score = tree.score(features_valid,target_valid) # calculate the accuracy score on the validation set\n",
    "        if score > best_tree:\n",
    "            best_tree = score # save the best accuracy score on the validation set\n",
    "            best_depth = depth # save the number of estimators corresponding to the best accuracy score\n",
    "            best_leaf = leaf\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (depth = {}): {}\".format(best_depth, best_tree))\n",
    "\n",
    "final_tree = DecisionTreeClassifier(random_state=54321, max_depth=best_depth, min_samples_leaf=best_leaf) # change `n_estimators` to obtain the best model\n",
    "final_tree.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that our best tree has a depth of 7 and 13 leaves on its branches. This model gives us an accuracy of 84.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"random-forest\"></a>\n",
    "## Model: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a good tree model, let's create a forest and give it space for these trees to grow freely. Although this may take more time, it can improve the accuracy of our model. In this case, I will take advantage of my machine's power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del mejor modelo en el conjunto de validación (n_estimators = 3): 0.8506998444790047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=11, min_samples_leaf=3, n_estimators=3,\n",
       "                       random_state=54321)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest = 0\n",
    "best_est = 0\n",
    "score=0\n",
    "best_leaf = 0\n",
    "best_depth = 0\n",
    "for est in range(1, 20): # select the hyperparameter range\n",
    "    for depth in range(1, 20): \n",
    "        for leaf in range(1,20):\n",
    "            forest = RandomForestClassifier(random_state=54321, n_estimators=est, max_depth=depth, min_samples_leaf=leaf) # configure the number of trees\n",
    "            forest.fit(features_train,target_train) # train the model on the training set\n",
    "            score = forest.score(features_valid,target_valid) # calculate the accuracy score on the validation set\n",
    "            if score > best_forest:\n",
    "                best_forest = score # save the best accuracy score on the validation set\n",
    "                best_est = est # save the number of estimators corresponding to the best accuracy score\n",
    "                best_leaf = leaf\n",
    "                best_depth = depth\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_forest))\n",
    "\n",
    "final_forest = RandomForestClassifier(random_state=54321, n_estimators=best_est, max_depth=best_depth, min_samples_leaf=best_leaf) # change `n_estimators` to obtain the best model\n",
    "\n",
    "final_forest.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the accuracy only increased slightly, we are close to 85.1%. Our final model has 3 trees, 11 depth, and 3 leaves. The significant depth might indicate overfitting; we'll see how this model performs in the testing phase.\n",
    "\n",
    "It could be argued that the processing time required is not worth the small gain achieved, but once found, this model does perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"regresion-logistica\"></a>\n",
    "## Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To not leave it behind, we will also test with logistic regression, although we do not expect to obtain a better model than the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.776049766718507"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LogisticRegression(random_state=54321, solver='liblinear')\n",
    "reg.fit(features_train,target_train)\n",
    "reg.score(features_valid,target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has little room for calibration, and even though various solvers were tested, its accuracy barely reaches 77.6%. We will continue with our forest model since it has the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"testeo\"></a>\n",
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that we have two models with very similar accuracies, we will conduct tests for each one. To do this, we will train the model we are testing with `df_rest`, which includes the original training and validation data. Once we have the trained model, we will compare it with the data in `df_test`. We expect to achieve a high accuracy percentage, above 84% if everything goes well.\n",
    "\n",
    "First, let's create the features and target for `df_rest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_rest = df_rest.drop(['is_ultra'], axis=1)\n",
    "target_rest = df_rest['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7807153965785381\n"
     ]
    }
   ],
   "source": [
    "final_forest= RandomForestClassifier(max_depth=11, min_samples_leaf=3, n_estimators=3, random_state=54321)\n",
    "final_forest.fit(features_rest,target_rest)\n",
    "\n",
    "score = final_forest.score(features_test, target_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this model has dropped by 7 percentage points. This is likely due to the overfitting of this model. We will test the decision tree model before taking further action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7729393468118196\n"
     ]
    }
   ],
   "source": [
    "final_tree = DecisionTreeClassifier(max_depth=7, min_samples_leaf=13, random_state=54321)\n",
    "final_tree.fit(features_rest, target_rest)\n",
    "\n",
    "score = final_tree.score(features_test, target_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the tree model has dropped again, while the forest model maintains its slight advantage.\n",
    "\n",
    "There should be a method to reduce these accuracy losses. For now, despite attempts to alter some other elements, it has not been possible to achieve a model with higher accuracy than these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calibrating and comparing our 3 models, we are left with 2 potential options:\n",
    "\n",
    "1. A tree with 7 branches and 13 leaves, achieving 77.3% accuracy in testing. A significant advantage is its high speed and accuracy. Although Option 2 has higher accuracy, it can be time-consuming. Code:\n",
    "\n",
    "   - `final_tree = DecisionTreeClassifier(max_depth=7, min_samples_leaf=13, random_state=54321)`\n",
    "\n",
    "2. A forest of 3 trees, with 11 branches and 3 leaves, achieving 78.1% accuracy in testing. This model may take a bit more time, but considering large data scales, the difference in accuracy with Option 1 starts to become significant. Code:\n",
    "\n",
    "   - `final_forest = RandomForestClassifier(max_depth=11, min_samples_leaf=3, n_estimators=3, random_state=54321)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
